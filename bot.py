import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL_NAME = "llama-3.1-8b-instruct"

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_html(
        "ü§ñ <b>Groq AI Vision Bot</b>\n\n"
        "üìù –ü–∏—à–∏ –≤–æ–ø—Ä–æ—Å—ã\n"
        "üñºÔ∏è –û—Ç–ø—Ä–∞–≤–ª—è–π —Ñ–æ—Ç–æ - —Ä–∞—Å–ø–æ–∑–Ω–∞—é!\n"
        "üí¨ <i>Llama 3.1 Vision</i>"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text
    try:
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ."},
                {"role": "user", "content": user_message}
            ],
            model=GROQ_MODEL_NAME,
            temperature=0.7,
            max_tokens=1024,
        )
        await update.message.reply_text(response.choices[0].message.content.strip())
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    photo = update.message.photo[-1]
    try:
        file = await context.bot.get_file(photo.file_id)
        photo_bytes = await file.download_as_bytearray()
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ: —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ, —Ü–≤–µ—Ç–∞, —ç–º–æ—Ü–∏–∏, —Ç–µ–∫—Å—Ç. –ù–∞ —Ä—É—Å—Å–∫–æ–º!"},
                {"role": "user", "content": [
                    {"type": "text", "text": "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ!"},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{photo_bytes.hex()}"}}
                ]}
            ],
            model="llama-3.1-8b-instruct",
            temperature=0.3,
            max_tokens=1500,
        )
        await update.message.reply_text(f"üñºÔ∏è <b>–ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ:</b>\n\n{response.choices[0].message.content.strip()}", parse_mode='HTML')
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ: {e}")

def main() -> None:
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    print("üöÄ Vision Bot –∑–∞–ø—É—â–µ–Ω!")
    application.run_polling()

if __name__ == '__main__':
    main()